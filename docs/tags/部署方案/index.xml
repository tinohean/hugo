<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>部署方案 on 半岛无风</title>
    <link>http://tinohean.top/tags/%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/</link>
    <description>Recent content in 部署方案 on 半岛无风</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Mar 2021 13:33:54 +0800</lastBuildDate><atom:link href="http://tinohean.top/tags/%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Paddle飞桨部署方案</title>
      <link>http://tinohean.top/p/paddle%E9%A3%9E%E6%A1%A8%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/</link>
      <pubDate>Tue, 02 Mar 2021 13:33:54 +0800</pubDate>
      
      <guid>http://tinohean.top/p/paddle%E9%A3%9E%E6%A1%A8%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88/</guid>
      <description>Paddle飞桨部署文档 Paddle是百度开源的一款深度学习平台
基础环境 环境说明    项 版本     GPU NVIDA Tesla P4   操作系统 ubuntu 18.04 x86_64   硬件规格 4C20G 1Mbps + 100GB   Python 3.7.10   包管理 Anaconda 3   telsa驱动 NVIDIA-Linux-x86_64-418.152.00   cuda驱动 cuda_10.1.243_418.87.00_linux    环境预设  检查显卡  lspci | grep -i nvidia 2.确认gcc版本,没有则安装
gcc --version 3.安装内核开发包
sudo apt-get install linux-headers-$(uname -r) 4.禁掉Nouveau驱动
echo &amp;#39;&amp;#39;&amp;#39;blacklist nouveau options nouveau modeset=0&amp;#39;&amp;#39;&amp;#39; | sudo tee /etc/modprobe.</description>
    </item>
    
    <item>
      <title>Kubeadm部署kubernetes高可用集群</title>
      <link>http://tinohean.top/p/kubeadm%E9%83%A8%E7%BD%B2kubernetes%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Fri, 14 Feb 2020 22:52:33 +0800</pubDate>
      
      <guid>http://tinohean.top/p/kubeadm%E9%83%A8%E7%BD%B2kubernetes%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4/</guid>
      <description>Kubeadm部署kubernetes高可用集群 前言 技术发展实在是快，之前还比较流行的keep-alived+HAProxy HA负载方案，如今(2021-11-2)已经大有被kube-vip取代的趋势。回过头来看当时写的部署文档，已然过时了。 趁着服务器空闲，修补下方案。
HA方案 对于kubernetes集群来说，高可用性指的是控制平面（包括etcd集群)的高可用。控制平面的组件中，kube-scheduler和kube-controller-manager通过etcd实现高可用选主，我们不需要额外操心。所以，实际的高可用方案，只要满足控制节点数量奇数且大于等于三，然后实现apiserver的高可用即可。
基于etcd集群的耦合性，高可用集群一般包括以下两种拓扑架构。
Stacked ectd topology etcd分布式存储集群堆叠在每一个控制面板节点上，作为控制平面的一个组件运行。
每个控制平面节点创建一个本地etcd成员，这个etcd成员只与本地的kube-apiserver通信。
 stacked etcd topology 
External etcd topology 外部etcd分布式数据存储集群在独立于控制平面节点的其他节点上运行。这样的话解耦了控制平面和etcd成员。 缺点是需要更多的服务器节点（至少三个）用于etcd集群部署。
 external etcd topology 
apiserver高可用实现 实现apiserver的高可用，主要是通过负载均衡技术，把请求转发到健康的节点上。
 apiserver 
 硬件LB
比如F5,Radware这类硬件负载技术。不过成本较高，好处是一般都自带维保合同。适合财大气粗的大厂。 软件LB 比如nginx代理，keep-alived + HAProxy，kube-vip  说到这里我其实觉得蛮遗憾的，为什么k8s不自己实现高可用呢，比如借助ipvs&amp;hellip;非要借助外部依赖增大架构复杂度。
本文主要介绍最新的kube-vip实现的高可用方案。
kube-vip 传统意义上的HA方案主要是通过keep-alived + HAProxy实现的，HAProxy是一个软件负载，但是存在单点问题，而keep-alived通过VRRP协议实现vip漂移从而达到热备的效果。
 keep-alived + HAProxy 
kube-vip是直接通过k8s构建的static pod，也可以配置为DaemonSet实现，通过ARP或者BGP协议实现冗余。
ARP协议下会选举出一个领导者，而BGP协议下所有节点都会广播VIP地址。优点也是显而易见的，架构简单，成本低，维护方便。
 前期准备 节点规划    主机名 角色 ip 配置 系统版本     master-1 master 172.</description>
    </item>
    
  </channel>
</rss>
