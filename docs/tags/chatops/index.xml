<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>chatops on 半岛无风</title>
    <link>http://tinohean.top/tags/chatops/</link>
    <description>Recent content in chatops on 半岛无风</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Sep 2021 23:51:08 +0800</lastBuildDate><atom:link href="http://tinohean.top/tags/chatops/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>浅谈ChatOps</title>
      <link>http://tinohean.top/p/%E6%B5%85%E8%B0%88chatops/</link>
      <pubDate>Thu, 02 Sep 2021 23:51:08 +0800</pubDate>
      
      <guid>http://tinohean.top/p/%E6%B5%85%E8%B0%88chatops/</guid>
      <description>浅谈ChatOps 背景 本文源自我在技术团队的一次分享。 八月的时候我调研了下ChatOps概念，并通过钉钉机器人成功落地。
至于当时为什么要做ChatOps呢，主要是因为实力不足（不懂算法，监控数据量有限），无法推进AIOps进行运维平台的迭代升级。而ChatOps作为一个新兴的概念（其实也不新了），也属于智能运维的范畴，在国内还没有什么很红的应用方案。
其次是当时出现了一些日常操作的痛点，比如某次研发小伙伴在午饭前上了一次线，午饭期间出现重大故障，只能捧着饭碗从食堂火速跑回工位回滚处理，再比如临睡前懒得去登陆监控页面的我想看下当前负载较大的服务器状况&amp;hellip;
在这样的契机下，经过一系列脑洞挖掘出一些潜在的用途后，一款python+dingtalk的简单原型就出来了。部署简单，实用，可定制性强。
概念 理解什么是ChatOps，只需要了解两个要点
 会话驱动 机器执行  也就是说，这个系统是通过对话式的聊天进行驱动的，而背后真正的执行者从人变成了机器人。
概念最早源于Github的Hubot项目，开发者可以通过在pull request页面@机器人进行一些常规的分支合并等操作。
比如当下火热的kubernetes代码库， 一个叫k8s-ci-robot的机器人频频出现在开发者的视线。当然它在ChatOps的实践上已经走得很成熟了，可以胜任的一些常规操作包括：提醒代码库管理者review期限, 自动测试，自动加标签，自动格式检查，自动关闭长时间的issue,随机指定管理人员进行代码review等等。
这在很大程度上减轻了项目的管理工作负担，从简化的流程上间接提高了效率。
优点 了解了什么是ChatOps后，我们可以总结下所谓的ChatOps能给我们带来什么？
概括下来，ChatOps大概有以下几个收益：
 公开透明 上下文共享 移动高效  第一个，显而易见的，所有操作都是在聊天平台中公开的，有聊天记录可以查询，所有人都能看到彼此的操作记录，由此带来的第二个好处，就是上下文共享，一些繁琐复杂的操作流程，可以通过查看记录了解进度，协调，这样工作承接会更加有序。
还有一个很明显的好处就是移动高效，因为我们的操作端从电脑转移到了手机，pad等移动设备，也不需要输入冗长的命令，做很多次点击等操作，实际上会提高处理效率。
使用场景 脑洞一番后，总结了一些可使用的场景。
第一个，运维巡检，比如哪个夜黑风高的晚上，临睡前的我预感不妙，要看下现在硬件容量有可能爆满的服务器详情，这样可以提前处理下。
另一个，就是告警查询，有时候告警泛滥，我如果不登陆监控页面的话，不清楚哪些告警已经处理了，哪些没有处理。这时候我可以@机器人来一个当前告警清单。
第三个呢，就是紧急回滚。如同前文所说，比如哪天我们上好线，初期观察没啥问题，出去吃饭了，结果吃饭过程中出现大量告警，直接@机器人回滚操作，简单又高效。
第四个呢，就是我们经常需要做的，硬件信息查询，比如服务器外网IP，硬件配置，比登陆CMDB查询方便多了。
&amp;hellip;
架构  ChatOps系统架构  一个完整的ChatOps落地包括这四个层面的架构，有人（不限于运维，研发，甚至可以是运营），有聊天平台（比如国内的钉钉，微信），有机器人（比如github的hubot），有支持机器人操作的基础设施，包括服务器，脚本，后端服务等等。
后端服务作为ChatOps的主要开发对象，暂时没有很契合的开源方案，需要开发者自己开发相关逻辑。
等级演变 下面分析下ChatOps的演变路线。  before ChatOps 
在ChatOps之前，运维是直接对接监控系统的，没有聊天软件来进行信息同步。同时，告警处理和事件处理等运维操作都是基于Ad-hoc命令，通过shell客户端进行的。  lv1 
到了Level1后呢，我们会针对告警创建不同的讨论群，比如某应用触发告警了，运维在群里通知开发进行处理。在这个层级，事件的发送者还是人。  lv2a 
Level 2A后，我们已经可以把这些告警信息、事件详情等进行分类通知，比如硬件类告警专门发到一个群，应用类告警发到另一个群。这时候，事件的发送者变成了监控系统，然后还支持事件恢复通知。  lv2b 
Level 2B支持从监控系统中拉取数据发送到聊天平台了，比如查询CMDB获取硬件信息，工单系统啊，监控指标啊等信息。此时信息更加丰富了。  lv3 
到了level3后就是全自动化的交互。比如可以更新工单，事件状态，发出指令并查看执行结果。最重要的是我们能通过聊天工具跟监控系统等内部系统进行交互。  lv4</description>
    </item>
    
  </channel>
</rss>
